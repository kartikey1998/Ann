{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_churn_predicition.csv')\n",
    "df = df.drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## under samling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5163 1869\n"
     ]
    }
   ],
   "source": [
    "churn_0, churn_1 = df.Churn.value_counts()\n",
    "print(churn_0, churn_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class0 = df[df.Churn==0]\n",
    "df_class1 = df[df.Churn==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>...</th>\n",
       "      <th>InternetService_DSL</th>\n",
       "      <th>InternetService_Fiber optic</th>\n",
       "      <th>InternetService_No</th>\n",
       "      <th>Contract_Month-to-month</th>\n",
       "      <th>Contract_One year</th>\n",
       "      <th>Contract_Two year</th>\n",
       "      <th>PaymentMethod_Bank transfer (automatic)</th>\n",
       "      <th>PaymentMethod_Credit card (automatic)</th>\n",
       "      <th>PaymentMethod_Electronic check</th>\n",
       "      <th>PaymentMethod_Mailed check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.197183</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3900</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.253521</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5363</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.690141</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802817</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4004</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.309859</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  SeniorCitizen  Partner  Dependents    tenure  PhoneService  \\\n",
       "843        1              0        1           1  0.197183             1   \n",
       "3900       0              0        0           0  0.253521             1   \n",
       "5363       1              1        0           0  0.690141             1   \n",
       "1373       1              0        1           1  0.802817             1   \n",
       "4004       1              0        1           1  0.309859             1   \n",
       "\n",
       "      MultipleLines  OnlineSecurity  OnlineBackup  DeviceProtection  ...  \\\n",
       "843               0               0             0                 0  ...   \n",
       "3900              0               0             0                 1  ...   \n",
       "5363              1               0             0                 1  ...   \n",
       "1373              1               0             1                 0  ...   \n",
       "4004              0               0             0                 0  ...   \n",
       "\n",
       "      InternetService_DSL  InternetService_Fiber optic  InternetService_No  \\\n",
       "843                     0                            0                   1   \n",
       "3900                    0                            1                   0   \n",
       "5363                    0                            1                   0   \n",
       "1373                    1                            0                   0   \n",
       "4004                    0                            0                   1   \n",
       "\n",
       "      Contract_Month-to-month  Contract_One year  Contract_Two year  \\\n",
       "843                         0                  1                  0   \n",
       "3900                        1                  0                  0   \n",
       "5363                        1                  0                  0   \n",
       "1373                        1                  0                  0   \n",
       "4004                        0                  0                  1   \n",
       "\n",
       "      PaymentMethod_Bank transfer (automatic)  \\\n",
       "843                                         0   \n",
       "3900                                        0   \n",
       "5363                                        0   \n",
       "1373                                        1   \n",
       "4004                                        0   \n",
       "\n",
       "      PaymentMethod_Credit card (automatic)  PaymentMethod_Electronic check  \\\n",
       "843                                       0                               0   \n",
       "3900                                      0                               0   \n",
       "5363                                      0                               1   \n",
       "1373                                      0                               0   \n",
       "4004                                      0                               0   \n",
       "\n",
       "      PaymentMethod_Mailed check  \n",
       "843                            1  \n",
       "3900                           1  \n",
       "5363                           0  \n",
       "1373                           0  \n",
       "4004                           1  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class0_us = df_class0.sample(churn_1)\n",
    "df_class0_us.shape\n",
    "df_us = pd.concat([df_class0_us, df_class1], axis = 0)\n",
    "df_us.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1869\n",
       "0    1869\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_us.Churn.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_us.drop('Churn', axis = 1)\n",
    "y = df_us['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 6, stratify =y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann(X_train, X_test, y_train, y_test):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(26,  input_shape= (26,), activation= 'relu'),\n",
    "        keras.layers.Dropout(.5),\n",
    "        keras.layers.Dense(10, activation= 'relu'),\n",
    "        keras.layers.Dropout(.5),\n",
    "        keras.layers.Dense(1, activation= 'sigmoid'),])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer = 'adam',\n",
    "        loss = 'binary_crossentropy',\n",
    "        metrics= 'accuracy')\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=100)\n",
    "    \n",
    "    y_pred = np.round(model.predict(X_test))\n",
    "    \n",
    "    from sklearn.metrics import classification_report\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(report)\n",
    "    return y_pred.reshape(len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "94/94 [==============================] - 1s 4ms/step - loss: 0.7357 - accuracy: 0.5044\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.6838 - accuracy: 0.5621\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.6631 - accuracy: 0.6081\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.6376 - accuracy: 0.6318\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.6208 - accuracy: 0.6717\n",
      "Epoch 6/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5958 - accuracy: 0.6908: 0s - loss: 0.5871 - accura\n",
      "Epoch 7/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.6024 - accuracy: 0.6880\n",
      "Epoch 8/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5779 - accuracy: 0.7012\n",
      "Epoch 9/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5736 - accuracy: 0.7217\n",
      "Epoch 10/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5810 - accuracy: 0.7144\n",
      "Epoch 11/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5676 - accuracy: 0.7248\n",
      "Epoch 12/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5601 - accuracy: 0.7271\n",
      "Epoch 13/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5616 - accuracy: 0.7278\n",
      "Epoch 14/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5527 - accuracy: 0.7469\n",
      "Epoch 15/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5585 - accuracy: 0.7156\n",
      "Epoch 16/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5485 - accuracy: 0.7300\n",
      "Epoch 17/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5455 - accuracy: 0.7230\n",
      "Epoch 18/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5511 - accuracy: 0.7336\n",
      "Epoch 19/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5372 - accuracy: 0.7617\n",
      "Epoch 20/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5527 - accuracy: 0.7279\n",
      "Epoch 21/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5343 - accuracy: 0.7516\n",
      "Epoch 22/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5201 - accuracy: 0.7665\n",
      "Epoch 23/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5318 - accuracy: 0.7509\n",
      "Epoch 24/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5409 - accuracy: 0.7583\n",
      "Epoch 25/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5351 - accuracy: 0.7508\n",
      "Epoch 26/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5352 - accuracy: 0.7571\n",
      "Epoch 27/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5337 - accuracy: 0.7452\n",
      "Epoch 28/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5118 - accuracy: 0.7821\n",
      "Epoch 29/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5477 - accuracy: 0.7502\n",
      "Epoch 30/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5402 - accuracy: 0.7656\n",
      "Epoch 31/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5313 - accuracy: 0.7606\n",
      "Epoch 32/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5368 - accuracy: 0.7556\n",
      "Epoch 33/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5484 - accuracy: 0.7518\n",
      "Epoch 34/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5164 - accuracy: 0.7656\n",
      "Epoch 35/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5179 - accuracy: 0.7702\n",
      "Epoch 36/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5314 - accuracy: 0.7623\n",
      "Epoch 37/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5215 - accuracy: 0.7686\n",
      "Epoch 38/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5241 - accuracy: 0.7585\n",
      "Epoch 39/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5142 - accuracy: 0.7676\n",
      "Epoch 40/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5117 - accuracy: 0.7680\n",
      "Epoch 41/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5164 - accuracy: 0.7723\n",
      "Epoch 42/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5288 - accuracy: 0.7600\n",
      "Epoch 43/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5171 - accuracy: 0.7671\n",
      "Epoch 44/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5263 - accuracy: 0.7667\n",
      "Epoch 45/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5155 - accuracy: 0.7666\n",
      "Epoch 46/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5239 - accuracy: 0.7750\n",
      "Epoch 47/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5095 - accuracy: 0.7650\n",
      "Epoch 48/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5405 - accuracy: 0.7540\n",
      "Epoch 49/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5190 - accuracy: 0.7558\n",
      "Epoch 50/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5188 - accuracy: 0.7645\n",
      "Epoch 51/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5325 - accuracy: 0.7672\n",
      "Epoch 52/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5201 - accuracy: 0.7607\n",
      "Epoch 53/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.5139 - accuracy: 0.76 - 0s 4ms/step - loss: 0.5135 - accuracy: 0.7648\n",
      "Epoch 54/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.7785\n",
      "Epoch 55/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.7707\n",
      "Epoch 56/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5146 - accuracy: 0.7691\n",
      "Epoch 57/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5075 - accuracy: 0.7816\n",
      "Epoch 58/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5270 - accuracy: 0.7619\n",
      "Epoch 59/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5221 - accuracy: 0.7568\n",
      "Epoch 60/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5202 - accuracy: 0.7665\n",
      "Epoch 61/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5146 - accuracy: 0.7662\n",
      "Epoch 62/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4994 - accuracy: 0.7712\n",
      "Epoch 63/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5114 - accuracy: 0.7742\n",
      "Epoch 64/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5167 - accuracy: 0.7731\n",
      "Epoch 65/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4999 - accuracy: 0.7845\n",
      "Epoch 66/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5103 - accuracy: 0.7686\n",
      "Epoch 67/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4997 - accuracy: 0.7714\n",
      "Epoch 68/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7802\n",
      "Epoch 69/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.7713\n",
      "Epoch 70/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5124 - accuracy: 0.7646\n",
      "Epoch 71/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.7569\n",
      "Epoch 72/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5090 - accuracy: 0.7711\n",
      "Epoch 73/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5224 - accuracy: 0.7677\n",
      "Epoch 74/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4872 - accuracy: 0.7865\n",
      "Epoch 75/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7698\n",
      "Epoch 76/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5019 - accuracy: 0.7742\n",
      "Epoch 77/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4942 - accuracy: 0.7815\n",
      "Epoch 78/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5134 - accuracy: 0.7850\n",
      "Epoch 79/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4967 - accuracy: 0.7727\n",
      "Epoch 80/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7686\n",
      "Epoch 81/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4999 - accuracy: 0.7887\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4948 - accuracy: 0.7754\n",
      "Epoch 83/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4919 - accuracy: 0.7738\n",
      "Epoch 84/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5083 - accuracy: 0.7668\n",
      "Epoch 85/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4936 - accuracy: 0.7808\n",
      "Epoch 86/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4884 - accuracy: 0.7764\n",
      "Epoch 87/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4905 - accuracy: 0.7737\n",
      "Epoch 88/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4891 - accuracy: 0.7832\n",
      "Epoch 89/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4941 - accuracy: 0.7812\n",
      "Epoch 90/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5003 - accuracy: 0.7703\n",
      "Epoch 91/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5186 - accuracy: 0.7645\n",
      "Epoch 92/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.7794\n",
      "Epoch 93/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7631\n",
      "Epoch 94/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4994 - accuracy: 0.7775\n",
      "Epoch 95/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4872 - accuracy: 0.7855\n",
      "Epoch 96/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4886 - accuracy: 0.7853\n",
      "Epoch 97/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5037 - accuracy: 0.7729\n",
      "Epoch 98/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4899 - accuracy: 0.7923\n",
      "Epoch 99/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5163 - accuracy: 0.7748\n",
      "Epoch 100/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7827\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.75      0.74       374\n",
      "           1       0.75      0.73      0.74       374\n",
      "\n",
      "    accuracy                           0.74       748\n",
      "   macro avg       0.74      0.74      0.74       748\n",
      "weighted avg       0.74      0.74      0.74       748\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
       "       1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0.,\n",
       "       1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
       "       1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
       "       1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
       "       1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.,\n",
       "       1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
       "       0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
       "       1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0.,\n",
       "       0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
       "       0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,\n",
       "       1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
       "       0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
       "       1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1.,\n",
       "       1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
       "       1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5163 1869\n"
     ]
    }
   ],
   "source": [
    "print(churn_0, churn_1)\n",
    "df_class1_os = df_class1.sample(churn_0, replace = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_os = pd.concat([df_class0, df_class1_os])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_os.drop('Churn', axis = 1)\n",
    "y = df_os['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 6, stratify =y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "259/259 [==============================] - 2s 4ms/step - loss: 0.7621 - accuracy: 0.5275\n",
      "Epoch 2/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.6200 - accuracy: 0.6390\n",
      "Epoch 3/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5783 - accuracy: 0.6922\n",
      "Epoch 4/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5598 - accuracy: 0.7226\n",
      "Epoch 5/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5627 - accuracy: 0.7313\n",
      "Epoch 6/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5516 - accuracy: 0.7344\n",
      "Epoch 7/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5436 - accuracy: 0.7317\n",
      "Epoch 8/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5306 - accuracy: 0.7436\n",
      "Epoch 9/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5412 - accuracy: 0.7443\n",
      "Epoch 10/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5329 - accuracy: 0.7455\n",
      "Epoch 11/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5379 - accuracy: 0.7512\n",
      "Epoch 12/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5267 - accuracy: 0.7505\n",
      "Epoch 13/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5309 - accuracy: 0.7402\n",
      "Epoch 14/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5155 - accuracy: 0.7557\n",
      "Epoch 15/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5257 - accuracy: 0.7469\n",
      "Epoch 16/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5241 - accuracy: 0.7487\n",
      "Epoch 17/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5178 - accuracy: 0.7524\n",
      "Epoch 18/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5177 - accuracy: 0.7532\n",
      "Epoch 19/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5190 - accuracy: 0.7599\n",
      "Epoch 20/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5175 - accuracy: 0.7527\n",
      "Epoch 21/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5150 - accuracy: 0.7541\n",
      "Epoch 22/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5165 - accuracy: 0.7513: \n",
      "Epoch 23/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5182 - accuracy: 0.7532\n",
      "Epoch 24/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5068 - accuracy: 0.7598\n",
      "Epoch 25/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5139 - accuracy: 0.7604\n",
      "Epoch 26/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5099 - accuracy: 0.7602\n",
      "Epoch 27/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5230 - accuracy: 0.7522\n",
      "Epoch 28/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5089 - accuracy: 0.7661\n",
      "Epoch 29/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5122 - accuracy: 0.7654\n",
      "Epoch 30/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5105 - accuracy: 0.7589\n",
      "Epoch 31/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5106 - accuracy: 0.7608\n",
      "Epoch 32/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5131 - accuracy: 0.7576\n",
      "Epoch 33/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5046 - accuracy: 0.7599\n",
      "Epoch 34/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4961 - accuracy: 0.7692\n",
      "Epoch 35/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5079 - accuracy: 0.7614\n",
      "Epoch 36/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5054 - accuracy: 0.7555\n",
      "Epoch 37/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5076 - accuracy: 0.7644\n",
      "Epoch 38/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5030 - accuracy: 0.7615\n",
      "Epoch 39/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4904 - accuracy: 0.7707\n",
      "Epoch 40/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5070 - accuracy: 0.7578\n",
      "Epoch 41/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4882 - accuracy: 0.7737\n",
      "Epoch 42/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4969 - accuracy: 0.7737\n",
      "Epoch 43/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4981 - accuracy: 0.7763\n",
      "Epoch 44/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4973 - accuracy: 0.7671\n",
      "Epoch 45/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5047 - accuracy: 0.7672\n",
      "Epoch 46/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5047 - accuracy: 0.7605\n",
      "Epoch 47/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4987 - accuracy: 0.7677\n",
      "Epoch 48/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4926 - accuracy: 0.7726\n",
      "Epoch 49/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5028 - accuracy: 0.7635\n",
      "Epoch 50/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4962 - accuracy: 0.7675\n",
      "Epoch 51/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4944 - accuracy: 0.7611\n",
      "Epoch 52/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4954 - accuracy: 0.7670\n",
      "Epoch 53/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4968 - accuracy: 0.7644\n",
      "Epoch 54/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4949 - accuracy: 0.7600\n",
      "Epoch 55/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5166 - accuracy: 0.7546\n",
      "Epoch 56/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4993 - accuracy: 0.7636\n",
      "Epoch 57/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5017 - accuracy: 0.7693\n",
      "Epoch 58/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4940 - accuracy: 0.7633\n",
      "Epoch 59/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4992 - accuracy: 0.7632\n",
      "Epoch 60/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4948 - accuracy: 0.7590\n",
      "Epoch 61/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4938 - accuracy: 0.7737\n",
      "Epoch 62/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4908 - accuracy: 0.7684\n",
      "Epoch 63/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4995 - accuracy: 0.7641\n",
      "Epoch 64/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4946 - accuracy: 0.7692\n",
      "Epoch 65/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4968 - accuracy: 0.7659\n",
      "Epoch 66/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5000 - accuracy: 0.7602\n",
      "Epoch 67/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4978 - accuracy: 0.7722\n",
      "Epoch 68/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5008 - accuracy: 0.7628\n",
      "Epoch 69/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4897 - accuracy: 0.7761\n",
      "Epoch 70/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4939 - accuracy: 0.7717\n",
      "Epoch 71/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4904 - accuracy: 0.7656\n",
      "Epoch 72/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4917 - accuracy: 0.7698\n",
      "Epoch 73/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4960 - accuracy: 0.7628\n",
      "Epoch 74/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4958 - accuracy: 0.7641\n",
      "Epoch 75/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5064 - accuracy: 0.7587\n",
      "Epoch 76/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4956 - accuracy: 0.7641\n",
      "Epoch 77/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4950 - accuracy: 0.7632\n",
      "Epoch 78/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4876 - accuracy: 0.7809\n",
      "Epoch 79/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4989 - accuracy: 0.7598\n",
      "Epoch 80/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5003 - accuracy: 0.7613\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4979 - accuracy: 0.7708\n",
      "Epoch 82/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4933 - accuracy: 0.7582\n",
      "Epoch 83/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4949 - accuracy: 0.7672\n",
      "Epoch 84/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5050 - accuracy: 0.7541\n",
      "Epoch 85/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5051 - accuracy: 0.7563\n",
      "Epoch 86/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4923 - accuracy: 0.7702\n",
      "Epoch 87/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4826 - accuracy: 0.7776\n",
      "Epoch 88/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4943 - accuracy: 0.7716\n",
      "Epoch 89/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4879 - accuracy: 0.7723\n",
      "Epoch 90/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4990 - accuracy: 0.7690\n",
      "Epoch 91/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4960 - accuracy: 0.7717\n",
      "Epoch 92/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4851 - accuracy: 0.7716\n",
      "Epoch 93/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4953 - accuracy: 0.7678\n",
      "Epoch 94/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4973 - accuracy: 0.7717\n",
      "Epoch 95/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4846 - accuracy: 0.7699\n",
      "Epoch 96/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4739 - accuracy: 0.7793\n",
      "Epoch 97/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4919 - accuracy: 0.7779\n",
      "Epoch 98/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5055 - accuracy: 0.7702\n",
      "Epoch 99/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4862 - accuracy: 0.7751\n",
      "Epoch 100/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4995 - accuracy: 0.7622\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.71      0.76      1033\n",
      "           1       0.75      0.85      0.79      1033\n",
      "\n",
      "    accuracy                           0.78      2066\n",
      "   macro avg       0.78      0.78      0.78      2066\n",
      "weighted avg       0.78      0.78      0.78      2066\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5163 1869\n"
     ]
    }
   ],
   "source": [
    "print(churn_0, churn_1)\n",
    "X = df.drop('Churn', axis = 1)\n",
    "y = df['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10326,)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy='minority')\n",
    "X_sm, y_sm = smote.fit_resample(X, y)\n",
    "y_sm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.6897 - accuracy: 0.5448\n",
      "Epoch 2/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5599 - accuracy: 0.7133\n",
      "Epoch 3/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5473 - accuracy: 0.7264\n",
      "Epoch 4/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5257 - accuracy: 0.7420\n",
      "Epoch 5/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5275 - accuracy: 0.7394\n",
      "Epoch 6/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5201 - accuracy: 0.7494\n",
      "Epoch 7/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5266 - accuracy: 0.7484\n",
      "Epoch 8/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5191 - accuracy: 0.7479\n",
      "Epoch 9/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5016 - accuracy: 0.7560\n",
      "Epoch 10/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5013 - accuracy: 0.7667\n",
      "Epoch 11/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5122 - accuracy: 0.7660\n",
      "Epoch 12/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4938 - accuracy: 0.7727\n",
      "Epoch 13/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4968 - accuracy: 0.7729\n",
      "Epoch 14/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.5061 - accuracy: 0.7668\n",
      "Epoch 15/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4952 - accuracy: 0.7785\n",
      "Epoch 16/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4887 - accuracy: 0.7697\n",
      "Epoch 17/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4927 - accuracy: 0.7692\n",
      "Epoch 18/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4935 - accuracy: 0.7751\n",
      "Epoch 19/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4886 - accuracy: 0.7814\n",
      "Epoch 20/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4907 - accuracy: 0.7740\n",
      "Epoch 21/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4976 - accuracy: 0.7690\n",
      "Epoch 22/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4977 - accuracy: 0.7789\n",
      "Epoch 23/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4923 - accuracy: 0.7728\n",
      "Epoch 24/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4882 - accuracy: 0.7805\n",
      "Epoch 25/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4838 - accuracy: 0.7776\n",
      "Epoch 26/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4855 - accuracy: 0.7827\n",
      "Epoch 27/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4988 - accuracy: 0.7700\n",
      "Epoch 28/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4899 - accuracy: 0.7830\n",
      "Epoch 29/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4843 - accuracy: 0.7789\n",
      "Epoch 30/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4826 - accuracy: 0.7824\n",
      "Epoch 31/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4790 - accuracy: 0.7836\n",
      "Epoch 32/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4772 - accuracy: 0.7824\n",
      "Epoch 33/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4858 - accuracy: 0.7763\n",
      "Epoch 34/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4762 - accuracy: 0.7793\n",
      "Epoch 35/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4758 - accuracy: 0.7840\n",
      "Epoch 36/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4789 - accuracy: 0.7763\n",
      "Epoch 37/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4827 - accuracy: 0.7764\n",
      "Epoch 38/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4873 - accuracy: 0.7824\n",
      "Epoch 39/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4846 - accuracy: 0.7822\n",
      "Epoch 40/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4800 - accuracy: 0.7866\n",
      "Epoch 41/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4788 - accuracy: 0.7882\n",
      "Epoch 42/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4696 - accuracy: 0.7815\n",
      "Epoch 43/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4761 - accuracy: 0.7885\n",
      "Epoch 44/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4850 - accuracy: 0.7812\n",
      "Epoch 45/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4752 - accuracy: 0.7803\n",
      "Epoch 46/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4722 - accuracy: 0.7867\n",
      "Epoch 47/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4743 - accuracy: 0.7871\n",
      "Epoch 48/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4790 - accuracy: 0.7840\n",
      "Epoch 49/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4830 - accuracy: 0.7876\n",
      "Epoch 50/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4825 - accuracy: 0.7776\n",
      "Epoch 51/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4875 - accuracy: 0.7771\n",
      "Epoch 52/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4873 - accuracy: 0.7767\n",
      "Epoch 53/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4780 - accuracy: 0.7782\n",
      "Epoch 54/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4707 - accuracy: 0.7856\n",
      "Epoch 55/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4767 - accuracy: 0.7866\n",
      "Epoch 56/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4785 - accuracy: 0.7794\n",
      "Epoch 57/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4727 - accuracy: 0.7890\n",
      "Epoch 58/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4718 - accuracy: 0.7881\n",
      "Epoch 59/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4650 - accuracy: 0.7947\n",
      "Epoch 60/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4771 - accuracy: 0.7806\n",
      "Epoch 61/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4685 - accuracy: 0.7861\n",
      "Epoch 62/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4832 - accuracy: 0.7828\n",
      "Epoch 63/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4723 - accuracy: 0.7844\n",
      "Epoch 64/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4675 - accuracy: 0.7924\n",
      "Epoch 65/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4776 - accuracy: 0.7869\n",
      "Epoch 66/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4655 - accuracy: 0.7888\n",
      "Epoch 67/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4809 - accuracy: 0.7797\n",
      "Epoch 68/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4755 - accuracy: 0.7974\n",
      "Epoch 69/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4755 - accuracy: 0.7893\n",
      "Epoch 70/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4682 - accuracy: 0.7934\n",
      "Epoch 71/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4641 - accuracy: 0.7983\n",
      "Epoch 72/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4758 - accuracy: 0.7863: \n",
      "Epoch 73/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4761 - accuracy: 0.7828\n",
      "Epoch 74/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4838 - accuracy: 0.7849\n",
      "Epoch 75/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4723 - accuracy: 0.7855: 0s\n",
      "Epoch 76/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4711 - accuracy: 0.7844\n",
      "Epoch 77/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4582 - accuracy: 0.7923\n",
      "Epoch 78/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4660 - accuracy: 0.7919\n",
      "Epoch 79/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4691 - accuracy: 0.7941\n",
      "Epoch 80/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4668 - accuracy: 0.8003\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4665 - accuracy: 0.7948\n",
      "Epoch 82/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4655 - accuracy: 0.7914\n",
      "Epoch 83/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4664 - accuracy: 0.7893\n",
      "Epoch 84/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4585 - accuracy: 0.8002\n",
      "Epoch 85/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4569 - accuracy: 0.7914\n",
      "Epoch 86/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4604 - accuracy: 0.7972\n",
      "Epoch 87/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4644 - accuracy: 0.7957\n",
      "Epoch 88/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4725 - accuracy: 0.7944\n",
      "Epoch 89/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4639 - accuracy: 0.7873\n",
      "Epoch 90/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4652 - accuracy: 0.7901\n",
      "Epoch 91/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4714 - accuracy: 0.7935\n",
      "Epoch 92/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4702 - accuracy: 0.7892\n",
      "Epoch 93/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4632 - accuracy: 0.7947\n",
      "Epoch 94/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4731 - accuracy: 0.7877\n",
      "Epoch 95/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4638 - accuracy: 0.7862\n",
      "Epoch 96/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4542 - accuracy: 0.8005\n",
      "Epoch 97/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4705 - accuracy: 0.7907\n",
      "Epoch 98/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4632 - accuracy: 0.8049\n",
      "Epoch 99/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4742 - accuracy: 0.7919\n",
      "Epoch 100/100\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 0.4630 - accuracy: 0.7946\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.78      0.80      1033\n",
      "           1       0.79      0.83      0.81      1033\n",
      "\n",
      "    accuracy                           0.80      2066\n",
      "   macro avg       0.80      0.80      0.80      2066\n",
      "weighted avg       0.80      0.80      0.80      2066\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sm, y_sm, test_size = 0.2, random_state = 6, stratify =y_sm )\n",
    "ann(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# By using Ensemble technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5163 1869\n"
     ]
    }
   ],
   "source": [
    "print(churn_0, churn_1)\n",
    "X = df.drop('Churn', axis = 1)\n",
    "y = df['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=6, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1033\n",
       "1     374\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>...</th>\n",
       "      <th>InternetService_Fiber optic</th>\n",
       "      <th>InternetService_No</th>\n",
       "      <th>Contract_Month-to-month</th>\n",
       "      <th>Contract_One year</th>\n",
       "      <th>Contract_Two year</th>\n",
       "      <th>PaymentMethod_Bank transfer (automatic)</th>\n",
       "      <th>PaymentMethod_Credit card (automatic)</th>\n",
       "      <th>PaymentMethod_Electronic check</th>\n",
       "      <th>PaymentMethod_Mailed check</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4548</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2900</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.281690</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.169014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  SeniorCitizen  Partner  Dependents    tenure  PhoneService  \\\n",
       "4548       0              0        0           0  0.014085             1   \n",
       "2072       1              0        0           0  0.000000             1   \n",
       "2900       1              0        1           0  0.281690             1   \n",
       "488        0              0        0           1  0.000000             1   \n",
       "3138       0              0        1           1  0.169014             1   \n",
       "\n",
       "      MultipleLines  OnlineSecurity  OnlineBackup  DeviceProtection  ...  \\\n",
       "4548              0               0             0                 0  ...   \n",
       "2072              0               0             0                 0  ...   \n",
       "2900              0               0             0                 1  ...   \n",
       "488               1               0             0                 0  ...   \n",
       "3138              1               0             1                 1  ...   \n",
       "\n",
       "      InternetService_Fiber optic  InternetService_No  \\\n",
       "4548                            1                   0   \n",
       "2072                            1                   0   \n",
       "2900                            1                   0   \n",
       "488                             1                   0   \n",
       "3138                            0                   0   \n",
       "\n",
       "      Contract_Month-to-month  Contract_One year  Contract_Two year  \\\n",
       "4548                        1                  0                  0   \n",
       "2072                        1                  0                  0   \n",
       "2900                        0                  1                  0   \n",
       "488                         1                  0                  0   \n",
       "3138                        1                  0                  0   \n",
       "\n",
       "      PaymentMethod_Bank transfer (automatic)  \\\n",
       "4548                                        0   \n",
       "2072                                        0   \n",
       "2900                                        0   \n",
       "488                                         0   \n",
       "3138                                        0   \n",
       "\n",
       "      PaymentMethod_Credit card (automatic)  PaymentMethod_Electronic check  \\\n",
       "4548                                      0                               1   \n",
       "2072                                      0                               1   \n",
       "2900                                      0                               1   \n",
       "488                                       0                               1   \n",
       "3138                                      0                               1   \n",
       "\n",
       "      PaymentMethod_Mailed check  Churn  \n",
       "4548                           0      1  \n",
       "2072                           0      1  \n",
       "2900                           0      0  \n",
       "488                            0      1  \n",
       "3138                           0      0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = X_train.copy()\n",
    "df2['Churn'] = y_train\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4130\n",
       "1    1495\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Churn'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1495, 27)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_class0 = df2[df2.Churn==0]\n",
    "df2_class1 = df2[df2.Churn==1]\n",
    "df2_class1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens1 = pd.concat([df_class0[0:1495], df_class1], axis = 0)\n",
    "df_ens2 = pd.concat([df_class0[1495:2990], df_class1], axis = 0)\n",
    "df_ens3 = pd.concat([df_class0[2990:], df_class1], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X1_train = df_ens1.drop('Churn', axis = 1)\n",
    "X2_train = df_ens2.drop('Churn', axis = 1)\n",
    "X3_train= df_ens3.drop('Churn', axis = 1)\n",
    "y1_train= df_ens1['Churn']\n",
    "y2_train = df_ens2['Churn']\n",
    "y3_train = df_ens3['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "106/106 [==============================] - 1s 4ms/step - loss: 0.8648 - accuracy: 0.5212\n",
      "Epoch 2/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.6602 - accuracy: 0.6017\n",
      "Epoch 3/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.6246 - accuracy: 0.6484\n",
      "Epoch 4/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.6060 - accuracy: 0.6817\n",
      "Epoch 5/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5818 - accuracy: 0.7072\n",
      "Epoch 6/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5670 - accuracy: 0.7374\n",
      "Epoch 7/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5515 - accuracy: 0.7250\n",
      "Epoch 8/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5509 - accuracy: 0.7087\n",
      "Epoch 9/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5414 - accuracy: 0.7256\n",
      "Epoch 10/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5145 - accuracy: 0.7512\n",
      "Epoch 11/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5388 - accuracy: 0.7483\n",
      "Epoch 12/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5403 - accuracy: 0.7357\n",
      "Epoch 13/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5325 - accuracy: 0.7410\n",
      "Epoch 14/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5306 - accuracy: 0.7469\n",
      "Epoch 15/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5222 - accuracy: 0.7469\n",
      "Epoch 16/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5199 - accuracy: 0.7464\n",
      "Epoch 17/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5521 - accuracy: 0.7275\n",
      "Epoch 18/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5246 - accuracy: 0.7436\n",
      "Epoch 19/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5377 - accuracy: 0.7418\n",
      "Epoch 20/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7645\n",
      "Epoch 21/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5306 - accuracy: 0.7527\n",
      "Epoch 22/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5142 - accuracy: 0.7500\n",
      "Epoch 23/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.7643\n",
      "Epoch 24/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5297 - accuracy: 0.7482\n",
      "Epoch 25/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5175 - accuracy: 0.7515\n",
      "Epoch 26/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5078 - accuracy: 0.7650\n",
      "Epoch 27/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.7607\n",
      "Epoch 28/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5167 - accuracy: 0.7566\n",
      "Epoch 29/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5187 - accuracy: 0.7593\n",
      "Epoch 30/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5235 - accuracy: 0.7544\n",
      "Epoch 31/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5081 - accuracy: 0.7509\n",
      "Epoch 32/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5156 - accuracy: 0.7559\n",
      "Epoch 33/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5087 - accuracy: 0.7592\n",
      "Epoch 34/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5187 - accuracy: 0.7559\n",
      "Epoch 35/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4979 - accuracy: 0.7629\n",
      "Epoch 36/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5092 - accuracy: 0.7734\n",
      "Epoch 37/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.7676\n",
      "Epoch 38/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.7711\n",
      "Epoch 39/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5103 - accuracy: 0.7620\n",
      "Epoch 40/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4863 - accuracy: 0.7814\n",
      "Epoch 41/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4965 - accuracy: 0.7669\n",
      "Epoch 42/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5028 - accuracy: 0.7550\n",
      "Epoch 43/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7611\n",
      "Epoch 44/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5082 - accuracy: 0.7591\n",
      "Epoch 45/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4978 - accuracy: 0.7692\n",
      "Epoch 46/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7654\n",
      "Epoch 47/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5219 - accuracy: 0.7553\n",
      "Epoch 48/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.7604\n",
      "Epoch 49/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4920 - accuracy: 0.7741\n",
      "Epoch 50/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4923 - accuracy: 0.7812\n",
      "Epoch 51/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5161 - accuracy: 0.7641\n",
      "Epoch 52/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5132 - accuracy: 0.7642\n",
      "Epoch 53/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5107 - accuracy: 0.7551\n",
      "Epoch 54/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4864 - accuracy: 0.7794\n",
      "Epoch 55/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5109 - accuracy: 0.7743\n",
      "Epoch 56/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4974 - accuracy: 0.7661\n",
      "Epoch 57/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5261 - accuracy: 0.7610\n",
      "Epoch 58/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4989 - accuracy: 0.7632\n",
      "Epoch 59/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4996 - accuracy: 0.7586\n",
      "Epoch 60/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4967 - accuracy: 0.7728\n",
      "Epoch 61/100\n",
      "106/106 [==============================] - ETA: 0s - loss: 0.4877 - accuracy: 0.76 - 0s 4ms/step - loss: 0.4881 - accuracy: 0.7637\n",
      "Epoch 62/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4768 - accuracy: 0.7863\n",
      "Epoch 63/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4824 - accuracy: 0.7691\n",
      "Epoch 64/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4886 - accuracy: 0.7688\n",
      "Epoch 65/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4945 - accuracy: 0.7670\n",
      "Epoch 66/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4836 - accuracy: 0.7695\n",
      "Epoch 67/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4936 - accuracy: 0.7780\n",
      "Epoch 68/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4992 - accuracy: 0.7630\n",
      "Epoch 69/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4959 - accuracy: 0.7712\n",
      "Epoch 70/100\n",
      "106/106 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.7642\n",
      "Epoch 71/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4863 - accuracy: 0.7734\n",
      "Epoch 72/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4818 - accuracy: 0.7753\n",
      "Epoch 73/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4976 - accuracy: 0.7689\n",
      "Epoch 74/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4916 - accuracy: 0.7798\n",
      "Epoch 75/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4913 - accuracy: 0.7694\n",
      "Epoch 76/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4989 - accuracy: 0.7545\n",
      "Epoch 77/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 0.7803\n",
      "Epoch 78/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7662\n",
      "Epoch 79/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4930 - accuracy: 0.7603\n",
      "Epoch 80/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4836 - accuracy: 0.7730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4961 - accuracy: 0.7641\n",
      "Epoch 82/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.7837\n",
      "Epoch 83/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4878 - accuracy: 0.7861\n",
      "Epoch 84/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5080 - accuracy: 0.7639\n",
      "Epoch 85/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4922 - accuracy: 0.7812\n",
      "Epoch 86/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4808 - accuracy: 0.7747\n",
      "Epoch 87/100\n",
      "106/106 [==============================] - 0s 3ms/step - loss: 0.4916 - accuracy: 0.7675\n",
      "Epoch 88/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4924 - accuracy: 0.7719\n",
      "Epoch 89/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4954 - accuracy: 0.7646\n",
      "Epoch 90/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7817\n",
      "Epoch 91/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7794\n",
      "Epoch 92/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7694\n",
      "Epoch 93/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4834 - accuracy: 0.7766\n",
      "Epoch 94/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.7685\n",
      "Epoch 95/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4802 - accuracy: 0.7850\n",
      "Epoch 96/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4944 - accuracy: 0.7624\n",
      "Epoch 97/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4866 - accuracy: 0.7722\n",
      "Epoch 98/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7593\n",
      "Epoch 99/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4878 - accuracy: 0.7800\n",
      "Epoch 100/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4831 - accuracy: 0.7881\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.68      0.79      1033\n",
      "           1       0.50      0.88      0.64       374\n",
      "\n",
      "    accuracy                           0.74      1407\n",
      "   macro avg       0.72      0.78      0.72      1407\n",
      "weighted avg       0.82      0.74      0.75      1407\n",
      "\n",
      "Epoch 1/100\n",
      "106/106 [==============================] - 1s 4ms/step - loss: 0.7574 - accuracy: 0.5149\n",
      "Epoch 2/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.6473 - accuracy: 0.6136\n",
      "Epoch 3/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.6141 - accuracy: 0.6695\n",
      "Epoch 4/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5831 - accuracy: 0.7125\n",
      "Epoch 5/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5795 - accuracy: 0.7267\n",
      "Epoch 6/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5693 - accuracy: 0.7316\n",
      "Epoch 7/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5475 - accuracy: 0.7434\n",
      "Epoch 8/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5427 - accuracy: 0.7462\n",
      "Epoch 9/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5458 - accuracy: 0.7586\n",
      "Epoch 10/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5547 - accuracy: 0.7373\n",
      "Epoch 11/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5352 - accuracy: 0.7544\n",
      "Epoch 12/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5341 - accuracy: 0.7444\n",
      "Epoch 13/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.7496\n",
      "Epoch 14/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5522 - accuracy: 0.7399\n",
      "Epoch 15/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5206 - accuracy: 0.7615\n",
      "Epoch 16/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5302 - accuracy: 0.7458\n",
      "Epoch 17/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5187 - accuracy: 0.7696\n",
      "Epoch 18/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5411 - accuracy: 0.7389\n",
      "Epoch 19/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5409 - accuracy: 0.7498\n",
      "Epoch 20/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5389 - accuracy: 0.7443\n",
      "Epoch 21/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5250 - accuracy: 0.7447\n",
      "Epoch 22/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5430 - accuracy: 0.7490\n",
      "Epoch 23/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5151 - accuracy: 0.7557\n",
      "Epoch 24/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5135 - accuracy: 0.7626\n",
      "Epoch 25/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5372 - accuracy: 0.7442\n",
      "Epoch 26/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5312 - accuracy: 0.7502\n",
      "Epoch 27/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5333 - accuracy: 0.7515\n",
      "Epoch 28/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5181 - accuracy: 0.7521\n",
      "Epoch 29/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5106 - accuracy: 0.7655\n",
      "Epoch 30/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.7680\n",
      "Epoch 31/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7625\n",
      "Epoch 32/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.7551\n",
      "Epoch 33/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5089 - accuracy: 0.7607\n",
      "Epoch 34/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5228 - accuracy: 0.7601\n",
      "Epoch 35/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5173 - accuracy: 0.7601\n",
      "Epoch 36/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5118 - accuracy: 0.7730\n",
      "Epoch 37/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4928 - accuracy: 0.7715\n",
      "Epoch 38/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5155 - accuracy: 0.7579\n",
      "Epoch 39/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.7669\n",
      "Epoch 40/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5021 - accuracy: 0.7705\n",
      "Epoch 41/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.7754\n",
      "Epoch 42/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.7638\n",
      "Epoch 43/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5296 - accuracy: 0.7465\n",
      "Epoch 44/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4952 - accuracy: 0.7716\n",
      "Epoch 45/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5267 - accuracy: 0.7501\n",
      "Epoch 46/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4932 - accuracy: 0.7885\n",
      "Epoch 47/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7594\n",
      "Epoch 48/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5180 - accuracy: 0.7692\n",
      "Epoch 49/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5168 - accuracy: 0.7681\n",
      "Epoch 50/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5179 - accuracy: 0.7625\n",
      "Epoch 51/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4930 - accuracy: 0.7677\n",
      "Epoch 52/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4974 - accuracy: 0.7647\n",
      "Epoch 53/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7654\n",
      "Epoch 54/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5248 - accuracy: 0.7527\n",
      "Epoch 55/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.7684\n",
      "Epoch 56/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5102 - accuracy: 0.7633\n",
      "Epoch 57/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5007 - accuracy: 0.7638\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7605\n",
      "Epoch 59/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5186 - accuracy: 0.7560\n",
      "Epoch 60/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.7659\n",
      "Epoch 61/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5006 - accuracy: 0.7735\n",
      "Epoch 62/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4965 - accuracy: 0.7700\n",
      "Epoch 63/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5106 - accuracy: 0.7758\n",
      "Epoch 64/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4975 - accuracy: 0.7661\n",
      "Epoch 65/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4974 - accuracy: 0.7720\n",
      "Epoch 66/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4965 - accuracy: 0.7698\n",
      "Epoch 67/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.7674\n",
      "Epoch 68/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5000 - accuracy: 0.7637\n",
      "Epoch 69/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4962 - accuracy: 0.7737\n",
      "Epoch 70/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4886 - accuracy: 0.7769\n",
      "Epoch 71/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4916 - accuracy: 0.7901\n",
      "Epoch 72/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7645\n",
      "Epoch 73/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4915 - accuracy: 0.7678\n",
      "Epoch 74/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.7700\n",
      "Epoch 75/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7833\n",
      "Epoch 76/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5088 - accuracy: 0.7757\n",
      "Epoch 77/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5151 - accuracy: 0.7677\n",
      "Epoch 78/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7621\n",
      "Epoch 79/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4986 - accuracy: 0.7669\n",
      "Epoch 80/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5124 - accuracy: 0.7668\n",
      "Epoch 81/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.7651\n",
      "Epoch 82/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.7633\n",
      "Epoch 83/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4838 - accuracy: 0.7645\n",
      "Epoch 84/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4990 - accuracy: 0.7642\n",
      "Epoch 85/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7781\n",
      "Epoch 86/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5006 - accuracy: 0.7635\n",
      "Epoch 87/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4995 - accuracy: 0.7681\n",
      "Epoch 88/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4980 - accuracy: 0.7777\n",
      "Epoch 89/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4898 - accuracy: 0.7719\n",
      "Epoch 90/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4997 - accuracy: 0.7626\n",
      "Epoch 91/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5008 - accuracy: 0.7701\n",
      "Epoch 92/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4875 - accuracy: 0.7635\n",
      "Epoch 93/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4990 - accuracy: 0.7677\n",
      "Epoch 94/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4818 - accuracy: 0.7787\n",
      "Epoch 95/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4940 - accuracy: 0.7718\n",
      "Epoch 96/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7819\n",
      "Epoch 97/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4955 - accuracy: 0.7595\n",
      "Epoch 98/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5000 - accuracy: 0.7625\n",
      "Epoch 99/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5243 - accuracy: 0.7432\n",
      "Epoch 100/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.4987 - accuracy: 0.7734\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.69      0.79      1033\n",
      "           1       0.50      0.86      0.63       374\n",
      "\n",
      "    accuracy                           0.73      1407\n",
      "   macro avg       0.71      0.77      0.71      1407\n",
      "weighted avg       0.82      0.73      0.75      1407\n",
      "\n",
      "Epoch 1/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: 0.7020 - accuracy: 0.5479\n",
      "Epoch 2/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6431 - accuracy: 0.6150\n",
      "Epoch 3/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5967 - accuracy: 0.6880\n",
      "Epoch 4/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5762 - accuracy: 0.6988\n",
      "Epoch 5/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5624 - accuracy: 0.7117\n",
      "Epoch 6/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5637 - accuracy: 0.7181\n",
      "Epoch 7/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5527 - accuracy: 0.7271\n",
      "Epoch 8/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5546 - accuracy: 0.7194\n",
      "Epoch 9/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5443 - accuracy: 0.7400\n",
      "Epoch 10/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5367 - accuracy: 0.7390\n",
      "Epoch 11/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5370 - accuracy: 0.7293\n",
      "Epoch 12/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5323 - accuracy: 0.7453\n",
      "Epoch 13/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5216 - accuracy: 0.7401\n",
      "Epoch 14/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: 0.5189 - accuracy: 0.7482\n",
      "Epoch 15/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.7587\n",
      "Epoch 16/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5322 - accuracy: 0.7380\n",
      "Epoch 17/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5265 - accuracy: 0.7428\n",
      "Epoch 18/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5429 - accuracy: 0.7380\n",
      "Epoch 19/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5147 - accuracy: 0.7512\n",
      "Epoch 20/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5121 - accuracy: 0.7498\n",
      "Epoch 21/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5279 - accuracy: 0.7623\n",
      "Epoch 22/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5165 - accuracy: 0.7493\n",
      "Epoch 23/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5114 - accuracy: 0.7528\n",
      "Epoch 24/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.7575\n",
      "Epoch 25/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.7636\n",
      "Epoch 26/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5240 - accuracy: 0.7443\n",
      "Epoch 27/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5181 - accuracy: 0.7684\n",
      "Epoch 28/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5168 - accuracy: 0.7508\n",
      "Epoch 29/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5127 - accuracy: 0.7652\n",
      "Epoch 30/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5296 - accuracy: 0.7524\n",
      "Epoch 31/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5275 - accuracy: 0.7545\n",
      "Epoch 32/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5075 - accuracy: 0.7567\n",
      "Epoch 33/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5032 - accuracy: 0.7569\n",
      "Epoch 34/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: 0.5114 - accuracy: 0.7574\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5156 - accuracy: 0.7517\n",
      "Epoch 36/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5164 - accuracy: 0.7651\n",
      "Epoch 37/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.7602\n",
      "Epoch 38/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5109 - accuracy: 0.7559\n",
      "Epoch 39/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7660\n",
      "Epoch 40/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5126 - accuracy: 0.7601\n",
      "Epoch 41/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5109 - accuracy: 0.7615\n",
      "Epoch 42/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.4996 - accuracy: 0.7611\n",
      "Epoch 43/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5220 - accuracy: 0.7661\n",
      "Epoch 44/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5178 - accuracy: 0.7610\n",
      "Epoch 45/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5034 - accuracy: 0.7558\n",
      "Epoch 46/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7655\n",
      "Epoch 47/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.4964 - accuracy: 0.7599\n",
      "Epoch 48/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: 0.5186 - accuracy: 0.7594\n",
      "Epoch 49/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.4961 - accuracy: 0.7730\n",
      "Epoch 50/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.4963 - accuracy: 0.7602\n",
      "Epoch 51/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5129 - accuracy: 0.7609\n",
      "Epoch 52/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5116 - accuracy: 0.7560\n",
      "Epoch 53/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7733\n",
      "Epoch 54/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5115 - accuracy: 0.7605\n",
      "Epoch 55/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.4982 - accuracy: 0.7624\n",
      "Epoch 56/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5076 - accuracy: 0.7657\n",
      "Epoch 57/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7733\n",
      "Epoch 58/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7669\n",
      "Epoch 59/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.4983 - accuracy: 0.7706\n",
      "Epoch 60/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.4909 - accuracy: 0.7619\n",
      "Epoch 61/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.4948 - accuracy: 0.7682\n",
      "Epoch 62/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.4949 - accuracy: 0.7736\n",
      "Epoch 63/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.4962 - accuracy: 0.7719\n",
      "Epoch 64/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.4823 - accuracy: 0.7709\n",
      "Epoch 65/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5018 - accuracy: 0.7655\n",
      "Epoch 66/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5008 - accuracy: 0.7541\n",
      "Epoch 67/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.4929 - accuracy: 0.7724\n",
      "Epoch 68/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5009 - accuracy: 0.7744\n",
      "Epoch 69/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5033 - accuracy: 0.7664\n",
      "Epoch 70/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.4995 - accuracy: 0.7645\n",
      "Epoch 71/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.4983 - accuracy: 0.7612\n",
      "Epoch 72/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.4969 - accuracy: 0.7738\n",
      "Epoch 73/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7714\n",
      "Epoch 74/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.4953 - accuracy: 0.7765\n",
      "Epoch 75/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.4958 - accuracy: 0.7858\n",
      "Epoch 76/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.4941 - accuracy: 0.7667\n",
      "Epoch 77/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.4952 - accuracy: 0.7702\n",
      "Epoch 78/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5126 - accuracy: 0.7705\n",
      "Epoch 79/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.4765 - accuracy: 0.7844\n",
      "Epoch 80/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.4939 - accuracy: 0.7700\n",
      "Epoch 81/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.4889 - accuracy: 0.7580\n",
      "Epoch 82/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.4958 - accuracy: 0.7647\n",
      "Epoch 83/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5111 - accuracy: 0.7745\n",
      "Epoch 84/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7956\n",
      "Epoch 85/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.4788 - accuracy: 0.7756\n",
      "Epoch 86/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.7778\n",
      "Epoch 87/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.4880 - accuracy: 0.7740\n",
      "Epoch 88/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5093 - accuracy: 0.7672\n",
      "Epoch 89/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.4757 - accuracy: 0.7863\n",
      "Epoch 90/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.4865 - accuracy: 0.7798\n",
      "Epoch 91/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.4968 - accuracy: 0.7689\n",
      "Epoch 92/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7753\n",
      "Epoch 93/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.4858 - accuracy: 0.7755\n",
      "Epoch 94/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.4865 - accuracy: 0.7682\n",
      "Epoch 95/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7518\n",
      "Epoch 96/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.4910 - accuracy: 0.7729\n",
      "Epoch 97/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.4866 - accuracy: 0.7802\n",
      "Epoch 98/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.4929 - accuracy: 0.7737\n",
      "Epoch 99/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5032 - accuracy: 0.7827\n",
      "Epoch 100/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.4935 - accuracy: 0.7681\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.78      0.84      1033\n",
      "           1       0.57      0.78      0.66       374\n",
      "\n",
      "    accuracy                           0.78      1407\n",
      "   macro avg       0.74      0.78      0.75      1407\n",
      "weighted avg       0.82      0.78      0.79      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ann_ens1 = ann(X1_train, X_test, y1_train, y_test)\n",
    "ann_ens2 = ann(X2_train, X_test, y2_train, y_test)\n",
    "ann_ens3 = ann(X3_train, X_test, y3_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True False ...  True  True  True]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1407"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ann_ens1==1)\n",
    "len(ann_ens1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    prediction = []\n",
    "    for i in range(len(ann_ens1)):\n",
    "        prediction.append(np.median([ann_ens1[i], ann_ens2[i], ann_ens3[i]]))\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3827    1\n",
       "4614    0\n",
       "4870    0\n",
       "2346    0\n",
       "4191    0\n",
       "3001    1\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.72      0.81      1033\n",
      "           1       0.52      0.86      0.65       374\n",
      "\n",
      "    accuracy                           0.75      1407\n",
      "   macro avg       0.73      0.79      0.73      1407\n",
      "weighted avg       0.82      0.75      0.77      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
